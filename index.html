<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="" />
    <meta name="author" content="" />
    <title>Algorithmic Bias</title>
    <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
    <!-- Font Awesome icons (free version)-->
    <script src="https://use.fontawesome.com/releases/v6.1.0/js/all.js" crossorigin="anonymous"></script>
    <!-- Google fonts-->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet"
        type="text/css" />
    <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
    <!-- Core theme CSS (includes Bootstrap)-->
    <link href="css/styles.css" rel="stylesheet" />
    <link href="css/myStyle.css" rel="stylesheet" />

</head>

<body id="page-top">
    <!-- Navigation-->
    <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
        <a class="navbar-brand js-scroll-trigger" href="#page-top">
            <span class="d-block d-lg-none">Algorithmic Bias</span>
            <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2"
                    src="assets/img/profile.jpg" alt="..." /></span>
        </a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive"
            aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span
                class="navbar-toggler-icon"></span></button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
            <ul class="navbar-nav">
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#algorithmic bias">Algorithmic Bias</a>
                </li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#what is it?">what is it?</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#examples">examples</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#prevention">Prevention</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#video">video</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#sources">sources</a></li>
            </ul>
        </div>
    </nav>
    <!-- Page Content-->
    <div class="container-fluid p-0">
        <!-- Algorithmic Bias-->
        <section class="resume-section" id="algorithmic bias">
            <div class="resume-section-content">
                <h1 class="mb-0">
                    Algorithmic
                    <span class="text-primary">Bias</span>
                </h1>
                <div class="subheading mb-5">
                    by Ingrid Lu · adv compsci 2023
                </div>
                <p class="lead mb-6">what is algorithmic bias and how do we prevent it?</p>
            </div>
        </section>
        <hr class="m-0" />
        <!-- What is it?-->
        <section class="resume-section" id="what is it?">
            <div class="resume-section-content">
                <h2 class="mb-5">what is it?</h2>
                <p><span class="tabSpace"></span>Algorithmic bias is when machine learning models and algorithms produce
                    results that are biased or unfair. “Bias” broadly means systematically less favorable outcomes
                    towards a specific group of people. This happens when the information and data used to train these
                    models were already biased to or against a particular group. Because our society is systematically
                    unjust, the data fed into these models could result in the algorithms being biased against a
                    specific community. Historical inequalities are seen to be amplified in algorithms that are fed
                    incomplete and biased data.
                </p>
            </div>
        </section>
        <hr class="m-0" />
        <!-- examples-->
        <section class="resume-section" id="examples">
            <div class="resume-section-content">
                <h2 class="mb-5">examples</h2>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1 post">

                        <div class="subheading mb-3 ">Amazon hiring AI</div>
                        <div> In 2014 Amazon tried to introduce a hiring AI that ideally would be able to be given 100
                            job applications and decide the top five, maximizing speed and efficiency. Quickly it was
                            revealed that the AI had a strong preference for men, taking off points for the word “women”
                            like in “women’s chess club”. This is because the AI taught itself what a good application
                            looked like by looking at applications from the last ten years, which were predominantly
                            male, reflecting how male-dominated the tech industry is. To this day most companies don’t
                            trust algorithms to do their recruiting.
                        </div>
                    </div>
                    <div class="flex-shrink-0"><span class="text-primary"></span></div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between">
                    <div class="flex-grow-1 post">

                        <div class="subheading mb-3">facial recognition</div>
                        <p>“According to the researchers, facial recognition technologies falsely identified Black and Asian faces 10 to 100 times more often than they did white faces.” women also tended to be confused more often than men. This is a result of mostly white and light-skinned faces being used to develop the facial recognition software instead of a completely diverse and well-rounded collection, with minorities properly represented.
                        </p>
                    </div>
                    <div class="flex-shrink-0"><span class="text-primary"></span></div>
                </div>

                <div class="d-flex flex-column flex-md-row justify-content-between">
                    <div class="flex-grow-1 post">

                        <div class="subheading mb-3">policing</div>
                        <p>A program that sent cops to places with more poc because data has shown that crime rates are higher in communities with more people of color because of historical discrimination. With more police sent there more crimes are caught, contributing to the bias that it’s a high crime area, leading even more police to go there, stuck in a loop and not paying attention to other areas. This amplifies bias and makes it impossible for things to change.
                        </p>
                    </div>
                    <div class="flex-shrink-0"><span class="text-primary"></span></div>
                </div>
            </div>
        </section>
        <hr class="m-0" />
        <!-- prevention-->
        <section class="resume-section" id="prevention">
            <div class="resume-section-content">
                <h2 class="mb-5">prevention</h2>
                <ul class="fa-ul mb-0">
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Ensure that the data used to train the algorithm is diverse and representative of the population it will be applied to.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Use techniques such as data pre-processing and augmentation to balance the dataset.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Use fairness constraints or regularization techniques to encourage the algorithm to make decisions that are fair and unbiased.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Regularly evaluate the algorithm for bias and make adjustments as needed.
                    </li>
                    <li><span class="fa-li"><i class="fas fa-check"></i></span>
                    Use Explainable AI (XAI) methods to make the decision-making process of the algorithm transparent and understandable.                    </li>
                </li>
                <li>
                    <span class="fa-li"><i class="fas fa-check"></i></span>
                    Have diverse team members involved in the design, development, and deployment of the algorithm.

                </li>
                <li>
                    <span class="fa-li"><i class="fas fa-check"></i></span>
                    Continuously monitor and audit the performance of the algorithm to detect and correct any bias that may arise over time.

                </li>
                <li>
                <span class="fa-li"><i class="fas fa-check"></i></span>
                Use multiple algorithms and ensemble methods to reduce bias and improve the robustness of the system.                    </li>
                </ul>
            </div>
        </section>
        <hr class="m-0" />
        <!-- video-->
        <section class="resume-section" id="video">
            <div class="resume-section-content">
                <h2 class="mb-5">video</h2>
                <!-- <video width = "640" height = "480" controls>
                        <source src="https://www.youtube.com/watch?v=gV0_raKR2UQ" type=video/ogg>
                    </video> -->
                <iframe width="840" height="472" src="https://www.youtube.com/embed/gV0_raKR2UQ"
                    title="YouTube video player" frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                    allowfullscreen></iframe>
            </div>
        </section>
        <hr class="m-0" />
        <!-- sources-->
        <section class="resume-section" id="sources">
            <div class="resume-section-content">
                <h2 class="mb-5">sources</h2>
                <ul class="fa-ul mb-0">
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        <a href="https://www.brookings.edu/research/algorithmic-bias-detection-and-mitigation-best-practices-and-policies-to-reduce-consumer-harms/">brookings.edu</a>
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        <a href="https://www.pwc.com/us/en/tech-effect/ai-analytics/algorithmic-bias-and-trust-in-ai.html">pwc.com</a> 
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        <a href="https://www.chicagobooth.edu/research/center-for-applied-artificial-intelligence/research/algorithmic-bias">chicagobooth.edu</a> 
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        <a href="https://insights.som.yale.edu/insights/can-bias-be-eliminated-from-algorithms">yale.edu</a>
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        <a href="https://www.liberties.eu/en/stories/algorithmic-bias-17052021/43528">liberties.eu</a>
                    </li>
                </ul>
            </div>
        </section>
    </div>
    <!-- Bootstrap core JS-->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Core theme JS-->
    <script src="js/scripts.js"></script>
</body>

</html>